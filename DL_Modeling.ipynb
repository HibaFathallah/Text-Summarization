{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7266371,"sourceType":"datasetVersion","datasetId":4211810},{"sourceId":7276959,"sourceType":"datasetVersion","datasetId":4218894}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.preprocessing.text import one_hot \nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:07:41.388279Z","iopub.execute_input":"2023-12-27T00:07:41.389131Z","iopub.status.idle":"2023-12-27T00:07:54.739132Z","shell.execute_reply.started":"2023-12-27T00:07:41.389097Z","shell.execute_reply":"2023-12-27T00:07:54.738146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = \"/kaggle/input/dataset/data.csv\"\ndf = pd.read_csv(file_path)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:07:54.740668Z","iopub.execute_input":"2023-12-27T00:07:54.741197Z","iopub.status.idle":"2023-12-27T00:08:03.547314Z","shell.execute_reply.started":"2023-12-27T00:07:54.741170Z","shell.execute_reply":"2023-12-27T00:08:03.546228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:08:16.393382Z","iopub.execute_input":"2023-12-27T00:08:16.394238Z","iopub.status.idle":"2023-12-27T00:08:16.399765Z","shell.execute_reply.started":"2023-12-27T00:08:16.394204Z","shell.execute_reply":"2023-12-27T00:08:16.398788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.sample(n=80000, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:08:24.307905Z","iopub.execute_input":"2023-12-27T00:08:24.308263Z","iopub.status.idle":"2023-12-27T00:08:24.328758Z","shell.execute_reply.started":"2023-12-27T00:08:24.308235Z","shell.execute_reply":"2023-12-27T00:08:24.327984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"\\n{type(df).__name__} shape: {df.shape}\")\nprint(f'\\nMissing Data: \\n{df.isnull().sum()}')\nprint(f'\\nDuplicates: {df.duplicated().sum()}')","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:09:25.577594Z","iopub.execute_input":"2023-12-27T00:09:25.578387Z","iopub.status.idle":"2023-12-27T00:09:25.760324Z","shell.execute_reply.started":"2023-12-27T00:09:25.578355Z","shell.execute_reply":"2023-12-27T00:09:25.759315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:08:27.817718Z","iopub.execute_input":"2023-12-27T00:08:27.818109Z","iopub.status.idle":"2023-12-27T00:08:27.861394Z","shell.execute_reply.started":"2023-12-27T00:08:27.818066Z","shell.execute_reply":"2023-12-27T00:08:27.860564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:09:29.977800Z","iopub.execute_input":"2023-12-27T00:09:29.978648Z","iopub.status.idle":"2023-12-27T00:09:30.147138Z","shell.execute_reply.started":"2023-12-27T00:09:29.978610Z","shell.execute_reply":"2023-12-27T00:09:30.146087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the median for text is equal to 272 so 50 % of the data has at least 272 words and the median for the summary is equal to 37 so 50% of the data has at least 37 words in it. \nSo we will be using these threshold to fix our data for the tokenization.\n\n* Q3(text)=450\n* Q3(summary)=63\n\nSince our data is huge (186 446 rows) and it will cause memory exhaustion, we need to reduce the size of the dataset and the preprocessing and data analysis was done to have an idea about our data to reduce it in a significant and clean method.","metadata":{}},{"cell_type":"code","source":"# Define the maximum allowed lengths\nmax_text_length = 450\nmax_headline_length = 63\n\n# Drop rows based on conditions\ndf = df[(df['text_length'] <= max_text_length) & (df['headline_length'] <= max_headline_length)]","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:09:07.497961Z","iopub.execute_input":"2023-12-27T00:09:07.498660Z","iopub.status.idle":"2023-12-27T00:09:07.509218Z","shell.execute_reply.started":"2023-12-27T00:09:07.498623Z","shell.execute_reply":"2023-12-27T00:09:07.508395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index_to_drop = 16189\ndf = df.drop(index_to_drop, axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:09:13.939246Z","iopub.execute_input":"2023-12-27T00:09:13.939725Z","iopub.status.idle":"2023-12-27T00:09:13.953872Z","shell.execute_reply.started":"2023-12-27T00:09:13.939682Z","shell.execute_reply":"2023-12-27T00:09:13.953034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:09:15.378038Z","iopub.execute_input":"2023-12-27T00:09:15.378757Z","iopub.status.idle":"2023-12-27T00:09:15.389461Z","shell.execute_reply.started":"2023-12-27T00:09:15.378720Z","shell.execute_reply":"2023-12-27T00:09:15.388381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:09:16.837897Z","iopub.execute_input":"2023-12-27T00:09:16.838248Z","iopub.status.idle":"2023-12-27T00:09:16.845765Z","shell.execute_reply.started":"2023-12-27T00:09:16.838221Z","shell.execute_reply":"2023-12-27T00:09:16.844801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of columns to drop\ncolumns_to_drop = ['text_length', 'headline_length']\n\n# Drop the specified columns\ndf = df.drop(columns=columns_to_drop)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:09:18.862939Z","iopub.execute_input":"2023-12-27T00:09:18.863784Z","iopub.status.idle":"2023-12-27T00:09:18.875913Z","shell.execute_reply.started":"2023-12-27T00:09:18.863749Z","shell.execute_reply":"2023-12-27T00:09:18.874787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:09:19.218104Z","iopub.execute_input":"2023-12-27T00:09:19.218477Z","iopub.status.idle":"2023-12-27T00:09:19.228339Z","shell.execute_reply.started":"2023-12-27T00:09:19.218445Z","shell.execute_reply":"2023-12-27T00:09:19.227276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"\\n{type(df).__name__} shape: {df.shape}\")\nprint(f'\\nMissing Data: \\n{df.isnull().sum()}')\nprint(f'\\nDuplicates: {df.duplicated().sum()}')","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:09:21.023034Z","iopub.execute_input":"2023-12-27T00:09:21.023834Z","iopub.status.idle":"2023-12-27T00:09:21.206026Z","shell.execute_reply.started":"2023-12-27T00:09:21.023798Z","shell.execute_reply":"2023-12-27T00:09:21.204943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" Adding special tokens like \"sostok\" (start of sequence) and \"eostok\" (end of sequence) is typically done in the target sequence (summary) for sequence-to-sequence tasks, including text summarization. The reason for this is to explicitly indicate the beginning and end of the target sequence, which helps the model during training and decoding. ","metadata":{}},{"cell_type":"code","source":"df['headline'] = df['headline'].apply(lambda x: '<go> ' + x + ' <stop>')","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:09:33.157878Z","iopub.execute_input":"2023-12-27T00:09:33.158602Z","iopub.status.idle":"2023-12-27T00:09:33.196858Z","shell.execute_reply.started":"2023-12-27T00:09:33.158568Z","shell.execute_reply":"2023-12-27T00:09:33.195883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:09:33.527867Z","iopub.execute_input":"2023-12-27T00:09:33.528232Z","iopub.status.idle":"2023-12-27T00:09:33.538157Z","shell.execute_reply.started":"2023-12-27T00:09:33.528200Z","shell.execute_reply":"2023-12-27T00:09:33.537086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First, split the data into training and validation sets\ndf_train, df_val = train_test_split(df, test_size=0.1, random_state=42)\n\n# Print the sizes of the sets\nprint(\"Training set size:\", len(df_train))\nprint(\"Validation set size:\", len(df_val))","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:09:35.262871Z","iopub.execute_input":"2023-12-27T00:09:35.263494Z","iopub.status.idle":"2023-12-27T00:09:35.277948Z","shell.execute_reply.started":"2023-12-27T00:09:35.263461Z","shell.execute_reply":"2023-12-27T00:09:35.276989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:09:36.207749Z","iopub.execute_input":"2023-12-27T00:09:36.208110Z","iopub.status.idle":"2023-12-27T00:09:36.217768Z","shell.execute_reply.started":"2023-12-27T00:09:36.208066Z","shell.execute_reply":"2023-12-27T00:09:36.216754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:darkblue\">  Tokenization and Padding**","metadata":{}},{"cell_type":"markdown","source":"Now for the Tokenization, we will be splitting the columns. In one dataframe we have the text, which is the input of our encoder and the dataframe heading which is the summary and will be the target and the output we are trying to achieve.","metadata":{}},{"cell_type":"markdown","source":"A tokenizer builds the vocabulary and converts a word sequence to an integer sequence. Go ahead and build tokenizers for text and summary:","metadata":{}},{"cell_type":"markdown","source":"### **<span style=\"color:darkred\">Train Set and Validation Set**","metadata":{}},{"cell_type":"code","source":"text = df_train['text']\nsummary = df_train['headline']","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:09:39.337750Z","iopub.execute_input":"2023-12-27T00:09:39.338342Z","iopub.status.idle":"2023-12-27T00:09:39.342942Z","shell.execute_reply.started":"2023-12-27T00:09:39.338307Z","shell.execute_reply":"2023-12-27T00:09:39.341815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_val = df_val['text']\nsummary_val = df_val['headline']","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:09:39.918014Z","iopub.execute_input":"2023-12-27T00:09:39.918722Z","iopub.status.idle":"2023-12-27T00:09:39.923257Z","shell.execute_reply.started":"2023-12-27T00:09:39.918691Z","shell.execute_reply":"2023-12-27T00:09:39.922131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:09:40.477910Z","iopub.execute_input":"2023-12-27T00:09:40.478763Z","iopub.status.idle":"2023-12-27T00:09:40.482756Z","shell.execute_reply.started":"2023-12-27T00:09:40.478730Z","shell.execute_reply":"2023-12-27T00:09:40.481727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<unk>')\nsummary_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters,oov_token='<unk>')\n\n\ntext_tokenizer.fit_on_texts(text)\nsummary_tokenizer.fit_on_texts(summary)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:09:41.059156Z","iopub.execute_input":"2023-12-27T00:09:41.059978Z","iopub.status.idle":"2023-12-27T00:09:49.371693Z","shell.execute_reply.started":"2023-12-27T00:09:41.059942Z","shell.execute_reply":"2023-12-27T00:09:49.370651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder_vocab_size = len(text_tokenizer.word_index) + 1\ndecoder_vocab_size = len(summary_tokenizer.word_index) + 1\n\n# vocab_size\nencoder_vocab_size, decoder_vocab_size","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:10:02.183056Z","iopub.execute_input":"2023-12-27T00:10:02.183946Z","iopub.status.idle":"2023-12-27T00:10:02.190218Z","shell.execute_reply.started":"2023-12-27T00:10:02.183909Z","shell.execute_reply":"2023-12-27T00:10:02.189251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = text_tokenizer.texts_to_sequences(text)\ntargets = summary_tokenizer.texts_to_sequences(summary)\n\ninputs_val = text_tokenizer.texts_to_sequences(text_val)\ntargets_val = summary_tokenizer.texts_to_sequences(summary_val)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:10:13.677775Z","iopub.execute_input":"2023-12-27T00:10:13.678146Z","iopub.status.idle":"2023-12-27T00:10:20.414386Z","shell.execute_reply.started":"2023-12-27T00:10:13.678110Z","shell.execute_reply":"2023-12-27T00:10:20.413586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example_index = 9897\nprint(\"Original Text Sequence:\")\nprint(summary[example_index])\n\nprint(\"\\nTokenized Text Sequence:\")\nprint(targets[example_index])","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:10:55.637672Z","iopub.execute_input":"2023-12-27T00:10:55.638345Z","iopub.status.idle":"2023-12-27T00:10:55.644862Z","shell.execute_reply.started":"2023-12-27T00:10:55.638314Z","shell.execute_reply":"2023-12-27T00:10:55.643783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder_maxlen = 400\ndecoder_maxlen = 75","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:11:43.527908Z","iopub.execute_input":"2023-12-27T00:11:43.528559Z","iopub.status.idle":"2023-12-27T00:11:43.532603Z","shell.execute_reply.started":"2023-12-27T00:11:43.528525Z","shell.execute_reply":"2023-12-27T00:11:43.531682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=encoder_maxlen, padding='post', truncating='post')\ntargets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=decoder_maxlen, padding='post', truncating='post')\n\ninputs_val = tf.keras.preprocessing.sequence.pad_sequences(inputs_val, maxlen=encoder_maxlen, padding='post', truncating='post')\ntargets_val = tf.keras.preprocessing.sequence.pad_sequences(targets_val, maxlen=decoder_maxlen, padding='post', truncating='post')","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:11:50.782654Z","iopub.execute_input":"2023-12-27T00:11:50.783023Z","iopub.status.idle":"2023-12-27T00:11:51.942299Z","shell.execute_reply.started":"2023-12-27T00:11:50.782994Z","shell.execute_reply":"2023-12-27T00:11:51.941476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To ensure that the data types of the tensors match the expected types for the model.","metadata":{}},{"cell_type":"code","source":"inputs = tf.cast(inputs, dtype=tf.int32)\ntargets = tf.cast(targets, dtype=tf.int32)\n\ninputs_val = tf.cast(inputs_val, dtype=tf.int32)\ntargets_val = tf.cast(targets_val, dtype=tf.int32)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:11:55.202749Z","iopub.execute_input":"2023-12-27T00:11:55.203143Z","iopub.status.idle":"2023-12-27T00:11:59.488225Z","shell.execute_reply.started":"2023-12-27T00:11:55.203108Z","shell.execute_reply":"2023-12-27T00:11:59.487403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* batch size determines the number of samples used in each training iterations\n* Shuffling is important during training to introduce randomness and prevent the model from learning the order of the data","metadata":{}},{"cell_type":"code","source":"BUFFER_SIZE = 10000\nBATCH_SIZE = 64","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:12:38.002553Z","iopub.execute_input":"2023-12-27T00:12:38.002928Z","iopub.status.idle":"2023-12-27T00:12:38.007290Z","shell.execute_reply.started":"2023-12-27T00:12:38.002901Z","shell.execute_reply":"2023-12-27T00:12:38.006245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\ndataset_val = tf.data.Dataset.from_tensor_slices((inputs_val,targets_val)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:12:39.077955Z","iopub.execute_input":"2023-12-27T00:12:39.078325Z","iopub.status.idle":"2023-12-27T00:12:39.100989Z","shell.execute_reply.started":"2023-12-27T00:12:39.078294Z","shell.execute_reply":"2023-12-27T00:12:39.099996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<span style=\"color:darkblue\">5.  Model Creation - <i>Transformer</i>**\n","metadata":{}},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:12:47.037584Z","iopub.execute_input":"2023-12-27T00:12:47.038570Z","iopub.status.idle":"2023-12-27T00:12:47.044015Z","shell.execute_reply.started":"2023-12-27T00:12:47.038532Z","shell.execute_reply":"2023-12-27T00:12:47.042784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef hist(history):\n    plt.title('Loss')\n\n    x= [i[0] for i in history['val']]\n    y=[i[1] for i in history['val']]\n    plt.plot(x,y,'x-')\n    \n    x= [i[0] for i in history['train']]\n    y=[i[1] for i in history['train']]    \n    plt.plot(x,y,'o-')\n\n    plt.legend(['validation','train'])\n    plt.show()\n    print('smallest val loss:', sorted(history['val'],key=lambda x: x[1])[0])","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:12:47.917958Z","iopub.execute_input":"2023-12-27T00:12:47.918829Z","iopub.status.idle":"2023-12-27T00:12:47.925741Z","shell.execute_reply.started":"2023-12-27T00:12:47.918791Z","shell.execute_reply":"2023-12-27T00:12:47.924782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Positional Encoding for adding notion of position among words","metadata":{}},{"cell_type":"markdown","source":"Positional Encoding is used for adding the notion of position among words.\nThey use wave frequencies to capture position information.","metadata":{}},{"cell_type":"code","source":"def get_angles(position, i, d_model):\n    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n    return position * angle_rates","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:12:52.237379Z","iopub.execute_input":"2023-12-27T00:12:52.237725Z","iopub.status.idle":"2023-12-27T00:12:52.243444Z","shell.execute_reply.started":"2023-12-27T00:12:52.237700Z","shell.execute_reply":"2023-12-27T00:12:52.242430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def positional_encoding(position, d_model):\n    angle_rads = get_angles(\n        np.arange(position)[:, np.newaxis],\n        np.arange(d_model)[np.newaxis, :],\n        d_model\n    )\n\n    # apply sin to even indices in the array; 2i\n    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n\n    # apply cos to odd indices in the array; 2i+1\n    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n\n    pos_encoding = angle_rads[np.newaxis, ...]\n\n    return tf.cast(pos_encoding, dtype=tf.float32)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:12:52.588003Z","iopub.execute_input":"2023-12-27T00:12:52.589016Z","iopub.status.idle":"2023-12-27T00:12:52.595386Z","shell.execute_reply.started":"2023-12-27T00:12:52.588981Z","shell.execute_reply":"2023-12-27T00:12:52.594216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **<span style=\"color:darkred\">Multi-Head Attention**\n","metadata":{}},{"cell_type":"markdown","source":"The term `d_model` refers to the total dimensionality or size of the model's representation for each element in the input sequence. It represents **the size of the hidden state**.\nIn the Transformer architecture, the input sequence is embedded into vectors of size `d_model` before being processed by the attention mechanism and feedforward neural networks.","metadata":{}},{"cell_type":"markdown","source":"**Multi-head attention** performs different parallel computations for the same word to achieve different results. These results are then connected to SoftMax to output the best suitable word.\n* The number of heads **`(num_heads)`** represents how many attention heads will be used in parallel.\n\n* The total dimension of the model **`(d_model)`** should be divisible by the number of heads.\n\n* **Weight Matrices**: Three dense layers are created for linear transformations of the input **(query, key, and value)** using weight matrices (`self.wq`, `self.wk`, `self.wv`).\n\n* **Output Transformation**: Another dense layer (self.dense) is used to transform the concatenated output of attention heads back to the original dimension (d_model)","metadata":{}},{"cell_type":"markdown","source":"<!-- Centering the image -->\n<div style=\"text-align:center\">\n  <!-- Inserting the image with a URL or file path -->\n  <img src=\"https://i.ibb.co/72q2k8Z/lalala.png\" alt=\"decod\" width=\"700\" height=\"400\">\n</div>","metadata":{}},{"cell_type":"code","source":"def scaled_dot_product_attention(q, k, v, mask):\n    matmul_qk = tf.matmul(q, k, transpose_b=True)\n\n    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n\n    if mask is not None:\n        scaled_attention_logits += (mask * -1e9)  \n\n    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n\n    output = tf.matmul(attention_weights, v)\n    return output, attention_weights","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:12:55.703347Z","iopub.execute_input":"2023-12-27T00:12:55.703778Z","iopub.status.idle":"2023-12-27T00:12:55.710036Z","shell.execute_reply.started":"2023-12-27T00:12:55.703747Z","shell.execute_reply":"2023-12-27T00:12:55.708952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MultiHeadAttention(tf.keras.layers.Layer):\n    def __init__(self, d_model, num_heads):\n        super(MultiHeadAttention, self).__init__()\n        self.num_heads = num_heads\n        self.d_model = d_model\n\n        assert d_model % self.num_heads == 0\n\n        self.depth = d_model // self.num_heads\n\n        self.wq = tf.keras.layers.Dense(d_model)\n        self.wk = tf.keras.layers.Dense(d_model)\n        self.wv = tf.keras.layers.Dense(d_model)\n\n        self.dense = tf.keras.layers.Dense(d_model)\n        \n    def split_heads(self, x, batch_size):\n        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n        return tf.transpose(x, perm=[0, 2, 1, 3])\n    \n    def call(self, v, k, q, mask):\n        batch_size = tf.shape(q)[0]\n\n        q = self.wq(q)\n        k = self.wk(k)\n        v = self.wv(v)\n\n        q = self.split_heads(q, batch_size)\n        k = self.split_heads(k, batch_size)\n        v = self.split_heads(v, batch_size)\n\n        scaled_attention, attention_weights = scaled_dot_product_attention(\n            q, k, v, mask)\n\n        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n\n        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n        output = self.dense(concat_attention)\n            \n        return output, attention_weights","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:12:56.497715Z","iopub.execute_input":"2023-12-27T00:12:56.498397Z","iopub.status.idle":"2023-12-27T00:12:56.509032Z","shell.execute_reply.started":"2023-12-27T00:12:56.498365Z","shell.execute_reply":"2023-12-27T00:12:56.507988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Feed Forward Network","metadata":{}},{"cell_type":"markdown","source":"The **Feed-Forward Network** consists of a fully connected (dense) layers with non-linear activation functions. It takes the output from the attention mechanism, processes it through one or more hidden layers, and produces an output that is then normalized and added to the original input.","metadata":{}},{"cell_type":"code","source":"def point_wise_feed_forward_network(d_model, dff):\n    return tf.keras.Sequential([\n        tf.keras.layers.Dense(dff, activation='relu'),\n        tf.keras.layers.Dense(d_model)\n    ])","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:12:58.717774Z","iopub.execute_input":"2023-12-27T00:12:58.718125Z","iopub.status.idle":"2023-12-27T00:12:58.723328Z","shell.execute_reply.started":"2023-12-27T00:12:58.718098Z","shell.execute_reply":"2023-12-27T00:12:58.722187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Masks","metadata":{}},{"cell_type":"code","source":"def create_masks(inp, tar):\n    enc_padding_mask = create_padding_mask(inp)\n    dec_padding_mask = create_padding_mask(inp)\n\n    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n    dec_target_padding_mask = create_padding_mask(tar)\n    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n  \n    return enc_padding_mask, combined_mask, dec_padding_mask\n\n\ndef create_padding_mask(seq):\n    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n    return seq[:, tf.newaxis, tf.newaxis, :]\n\ndef create_look_ahead_mask(size):\n    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n    return mask","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:13:47.598540Z","iopub.execute_input":"2023-12-27T00:13:47.599304Z","iopub.status.idle":"2023-12-27T00:13:47.608480Z","shell.execute_reply.started":"2023-12-27T00:13:47.599260Z","shell.execute_reply":"2023-12-27T00:13:47.607359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **<span style=\"color:darkred\">Encoder**\n","metadata":{}},{"cell_type":"markdown","source":"The **Encoder** class represents the entire encoder of the transformer model, consisting of multiple encoder layers.It includes:\n* **Embedding layer:** `(self.embedding)` to convert input tokens into vectors.\n* **Positional encoding:** `(self.pos_encoding)` to provide positional information to the model.\n* **EncoderLayer instances:** `(self.enc_layers)`.\n\nThe **EncoderLayer** class represents one layer within that encoder.\nIt takes as input the output of the encoder layer and it contains three main sub-layers:\n* **1. Multi-Head Self-Attention:** `(self.mha)` Processes the input sequence with attention to itself.\n\n* **Dropout and Normalization:** `(out1)` : used to avoid overfitting\n\n* **2. Feed-Forward Network :** `(ffn_output)` to convert target tokens into vectors.\n\n* **Dropout and Normalization:** `(out2)` Normalization ensures that the mean of each feature is close to zero, and the standard deviation is close to one, and so for stability of values. \n\n","metadata":{}},{"cell_type":"markdown","source":"<!-- Centering the image -->\n<div style=\"text-align:center\">\n  <!-- Inserting the image with a URL or file path -->\n  <img src=\"https://i.ibb.co/P18VGqw/wowow.png\" alt=\"decod\" width=\"300\" height=\"200\">\n</div>","metadata":{}},{"cell_type":"code","source":" class Encoder(tf.keras.layers.Layer):\n    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n        super(Encoder, self).__init__()\n\n        self.d_model = d_model\n        self.num_layers = num_layers\n        # Initialization of the Embedding Layer\n        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n        \n        # Initialization of the Positional Encoding\n        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n        \n        # Initialization of the EncoderLayer and loop through the different layers\n        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n\n        self.dropout = tf.keras.layers.Dropout(rate)\n        \n    def call(self, x, training, mask):\n        seq_len = tf.shape(x)[1]\n\n        x = self.embedding(x)\n        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n        x += self.pos_encoding[:, :seq_len, :]\n\n        x = self.dropout(x, training=training)\n    \n        for i in range(self.num_layers):\n            x = self.enc_layers[i](x, training, mask)\n    \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:13:04.657963Z","iopub.execute_input":"2023-12-27T00:13:04.658325Z","iopub.status.idle":"2023-12-27T00:13:04.668387Z","shell.execute_reply.started":"2023-12-27T00:13:04.658296Z","shell.execute_reply":"2023-12-27T00:13:04.667315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EncoderLayer(tf.keras.layers.Layer):\n    def __init__(self, d_model, num_heads, dff, rate=0.1):\n        super(EncoderLayer, self).__init__()\n        \n        #Initialization of MultiHeadAttention\n        self.mha = MultiHeadAttention(d_model, num_heads)\n        #Initialization of FFN \n        self.ffn = point_wise_feed_forward_network(d_model, dff)\n\n        #Initialization of the Normalization and Dropout Layers\n        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n\n        self.dropout1 = tf.keras.layers.Dropout(rate)\n        self.dropout2 = tf.keras.layers.Dropout(rate)\n    \n    def call(self, x, training, mask):\n        attn_output, _ = self.mha(x, x, x, mask)\n        attn_output = self.dropout1(attn_output, training=training)\n        out1 = self.layernorm1(x + attn_output)\n\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output, training=training)\n        out2 = self.layernorm2(out1 + ffn_output)\n\n        return out2","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:13:07.837902Z","iopub.execute_input":"2023-12-27T00:13:07.838279Z","iopub.status.idle":"2023-12-27T00:13:07.847179Z","shell.execute_reply.started":"2023-12-27T00:13:07.838248Z","shell.execute_reply":"2023-12-27T00:13:07.846142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **<span style=\"color:darkred\">Decoder**","metadata":{}},{"cell_type":"markdown","source":" The **Decoder** class represents the entire decoder of the transformer model, consisting of multiple decoder layers.It includes:\n* **Embedding layer:** `(self.embedding)` to convert target tokens into vectors.\n* **Positional encoding:** `(self.pos_encoding)` to provide positional information to the model.\n* **DecoderLayer instances:** `(self.dec_layers)`.\n\n\nThe **DecoderLayer** class represents one layer within that decoder.\nIt takes as input the output of the encoder layer and it contains three main sub-layers:\n* **1. Multi-Head Self-Attention:** `(self.mha1)` Processes the input sequence with attention to itself.\n\n* **Dropout and Normalization:** `(out1)` : used to avoid overfitting\n\n* **2. Multi-Head Attention with Encoder Output :** `(self.mha2)` to convert target tokens into vectors.\n\n* **Dropout and Normalization:** `(out2)` Normalization ensures that the mean of each feature is close to zero, and the standard deviation is close to one, and so for stability of values. \n\n* **3. Feed-Forward Network :** `(ffn_output)` to convert target tokens into vectors.\n\n* **Dropout and Normalization:** `(out3)`","metadata":{}},{"cell_type":"markdown","source":"<!-- Centering the image -->\n<div style=\"text-align:center\">\n  <!-- Inserting the image with a URL or file path -->\n  <img src=\"https://i.ibb.co/tb7GGhY/out2.png\" alt=\"decod\" width=\"300\" height=\"100\">\n</div>","metadata":{}},{"cell_type":"code","source":"class Decoder(tf.keras.layers.Layer):\n    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n        super(Decoder, self).__init__()\n        \n        #Represents the entire decoder of the transformer model, consisting of multiple layers \n        self.d_model = d_model\n        self.num_layers = num_layers\n        \n        # Initialization of the Embedding Layer\n        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n        \n        # Initialization of the Positional Encoding\n        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n        \n        # Initialization of the DecoderLayer and loop through the different layers\n        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n        self.dropout = tf.keras.layers.Dropout(rate)\n    \n    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n        seq_len = tf.shape(x)[1]\n        attention_weights = {}\n        # The variable x represents the input sequence to the decoder.\n        #It is first passed through the Embedding Layer\n        x = self.embedding(x)\n        \n        #It is then scaled \n        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n        \n        #The positional encoding is added to x.\n        x += self.pos_encoding[:, :seq_len, :]\n        \n        #Droput is applied for regularization.\n        x = self.dropout(x, training=training)\n        \n        #The loop iterates through the decoder layers (self.dec_layers).\n        for i in range(self.num_layers):\n            #For every input of the decoder, it will take the encoders output\n            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n            #the attention mechanism applied to the decoder's input sequence.\n            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n    \n        return x, attention_weights","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:13:15.162883Z","iopub.execute_input":"2023-12-27T00:13:15.163519Z","iopub.status.idle":"2023-12-27T00:13:15.173873Z","shell.execute_reply.started":"2023-12-27T00:13:15.163485Z","shell.execute_reply":"2023-12-27T00:13:15.172952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DecoderLayer(tf.keras.layers.Layer):\n    def __init__(self, d_model, num_heads, dff, rate=0.1):\n        super(DecoderLayer, self).__init__()\n        #Initialization of MultiHeadAttention \n        self.mha1 = MultiHeadAttention(d_model, num_heads)\n        self.mha2 = MultiHeadAttention(d_model, num_heads)\n        \n        #Initialization of FFN \n        self.ffn = point_wise_feed_forward_network(d_model, dff)\n        \n        #Initialization of the Normalization and Dropout Layers\n        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n\n        self.dropout1 = tf.keras.layers.Dropout(rate)\n        self.dropout2 = tf.keras.layers.Dropout(rate)\n        self.dropout3 = tf.keras.layers.Dropout(rate)\n    \n    \n    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n        # Multi-Head Attention (First Sub-Layer)\n        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n        \n        #Dropout and Normalization\n        attn1 = self.dropout1(attn1, training=training)\n        out1 = self.layernorm1(attn1 + x)\n        \n        # Multi-Head Attention with Encoder Output (Second Sub-Layer)\n        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n        \n        #Dropout and Normalization\n        attn2 = self.dropout2(attn2, training=training)\n        out2 = self.layernorm2(attn2 + out1)\n        \n        #Feed-Forward Network (Third Sub-Layer)\n        ffn_output = self.ffn(out2)\n        ffn_output = self.dropout3(ffn_output, training=training)\n        out3 = self.layernorm3(ffn_output + out2)\n\n        return out3, attn_weights_block1, attn_weights_block2","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:13:19.207825Z","iopub.execute_input":"2023-12-27T00:13:19.208665Z","iopub.status.idle":"2023-12-27T00:13:19.218915Z","shell.execute_reply.started":"2023-12-27T00:13:19.208629Z","shell.execute_reply":"2023-12-27T00:13:19.217915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<!-- Centering the image -->\n<div style=\"text-align:center\">\n  <!-- Inserting the image with a URL or file path -->\n  <img src=\"https://i.ibb.co/8PCxvvV/input-tokens.jpg\" alt=\"decod\" width=\"600\" height=\"400\">\n</div>","metadata":{}},{"cell_type":"markdown","source":"### **<span style=\"color:darkred\">Transformer**","metadata":{}},{"cell_type":"markdown","source":" The **Transformer** class inherits from `tf.keras.Model`. The parameter for initializing an instance(object) of the class are the following:\n* **`num_layers`:** Number of layers in both the encoder and decoder.\n* **`d_model`:** Dimensionality of the model, which is the size of the embedding vectors and the expected output of each sub-layer.\n* **`num_heads`:** Number of attention heads in the multi-head attention models.\n* **`dff`:** Dimensionality of the feedforward network.\n* **`input_vocab_size`:** Vocabulary size of the input.\n* **`target_vocab_size`:** Vocabulary size of the target output.\n* **`pe_input`:** Maximum sequence length for positional encoding in the input.\n* **`pe_target`:** Maximum sequence length for positional encoding in the target.\n* **`rate`:** Dropout rate (default is 0.1).\n \nThe **__init__** method is responsible for initializing the components, while the **call** method defines how these components are applied to input data during the forward pass.","metadata":{}},{"cell_type":"code","source":"class Transformer(tf.keras.Model):\n    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n        super(Transformer, self).__init__()\n        #creates an instance of the Encoder class\n        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n        #creates an instance of the Encoder class\n        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n\n        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n    \n    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n        #Encoder that takes the data as the input\n        enc_output = self.encoder(inp, training, enc_padding_mask)\n        #Decoder that takes as input the encoder output \n        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n        #Final layer \n        final_output = self.final_layer(dec_output)\n\n        return final_output, attention_weights","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:14:39.522806Z","iopub.execute_input":"2023-12-27T00:14:39.523548Z","iopub.status.idle":"2023-12-27T00:14:39.531498Z","shell.execute_reply.started":"2023-12-27T00:14:39.523514Z","shell.execute_reply":"2023-12-27T00:14:39.530401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<!-- Centering the image -->\n<div style=\"text-align:center\">\n  <!-- Inserting the image with a URL or file path -->\n  <img src=\"https://d2mk45aasx86xg.cloudfront.net/Transformer_architecture_a1d5ffc1e9.webp\" alt=\"decod\" width=\"300\" height=\"200\">\n</div>","metadata":{}},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"markdown","source":"#### Adam optimizer with custom learning rate scheduling","metadata":{}},{"cell_type":"code","source":"# hyper-params\nnum_layers = 5\nd_model = 128\ndff = 512\nnum_heads = 8\nEPOCHS = 15","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:49:10.142820Z","iopub.execute_input":"2023-12-27T00:49:10.143572Z","iopub.status.idle":"2023-12-27T00:49:10.148081Z","shell.execute_reply.started":"2023-12-27T00:49:10.143541Z","shell.execute_reply":"2023-12-27T00:49:10.146894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Defining losses and other metrics","metadata":{}},{"cell_type":"markdown","source":"* This algorithm is used to accelerate the gradient descent algorithm by taking into consideration the ‘exponentially weighted average’ of the gradients. Using averages makes the algorithm converge towards the minima in a faster pace. ","metadata":{}},{"cell_type":"code","source":"# determines the step size during optimization\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:49:13.677771Z","iopub.execute_input":"2023-12-27T00:49:13.678352Z","iopub.status.idle":"2023-12-27T00:49:13.687719Z","shell.execute_reply.started":"2023-12-27T00:49:13.678320Z","shell.execute_reply":"2023-12-27T00:49:13.686831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* SparseCategoricalCrossentropy is suitable for integer-encoded targets.\nEach word in the vocabulary is assigned a unique integer index.","metadata":{}},{"cell_type":"code","source":"loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:49:14.667607Z","iopub.execute_input":"2023-12-27T00:49:14.668232Z","iopub.status.idle":"2023-12-27T00:49:14.672737Z","shell.execute_reply.started":"2023-12-27T00:49:14.668199Z","shell.execute_reply":"2023-12-27T00:49:14.671736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* This function calculates the loss for a batch of predictions (pred) given the true labels (real) using the **sparse categorical crossentropy loss**.","metadata":{}},{"cell_type":"code","source":"def loss_function(real, pred):\n    mask = tf.math.logical_not(tf.math.equal(real, 0))\n    \n    #Calculates the loss for each example in the batch.\n    loss_ = loss_object(real, pred)\n    \n    #Converts the mask to the same data type as the loss.\n    mask = tf.cast(mask, dtype=loss_.dtype)\n    \n    #Applies the mask to the calculated loss, setting the loss to 0 for padded elements.\n    loss_ *= mask\n    #Computes the average loss over the non-padded elements in the batch\n    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:49:18.008254Z","iopub.execute_input":"2023-12-27T00:49:18.009176Z","iopub.status.idle":"2023-12-27T00:49:18.015108Z","shell.execute_reply.started":"2023-12-27T00:49:18.009131Z","shell.execute_reply":"2023-12-27T00:49:18.013921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history={'val':[],'train':[]}\ntrain_loss = tf.keras.metrics.Mean(name='train_loss')\nval_loss = tf.keras.metrics.Mean(name='val_loss')","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:49:18.242737Z","iopub.execute_input":"2023-12-27T00:49:18.243061Z","iopub.status.idle":"2023-12-27T00:49:18.258100Z","shell.execute_reply.started":"2023-12-27T00:49:18.243033Z","shell.execute_reply":"2023-12-27T00:49:18.257223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Defining the Transformer for Training","metadata":{}},{"cell_type":"code","source":"transformer = Transformer(\n    num_layers, \n    d_model, \n    num_heads, \n    dff,\n    input_vocab_size=encoder_vocab_size, \n    target_vocab_size=decoder_vocab_size, \n    pe_input=encoder_vocab_size, \n    pe_target=decoder_vocab_size,\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:49:21.087787Z","iopub.execute_input":"2023-12-27T00:49:21.088122Z","iopub.status.idle":"2023-12-27T00:49:21.581456Z","shell.execute_reply.started":"2023-12-27T00:49:21.088095Z","shell.execute_reply":"2023-12-27T00:49:21.580477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Training steps","metadata":{}},{"cell_type":"code","source":"@tf.function\ndef train_step(inp, tar):\n    tar_inp = tar[:, :-1]\n    tar_real = tar[:, 1:]\n    # Create masks for encoder, decoder\n    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n    \n    #This block starts a gradient tape to record operations for automatic differentiation.\n    with tf.GradientTape() as tape:\n        predictions, _ = transformer(\n            inp, tar_inp, \n            True, \n            enc_padding_mask, \n            combined_mask, \n            dec_padding_mask\n        )\n        #This line calculates the gradients of the loss \n        loss = loss_function(tar_real, predictions)\n    \n    #applies the calculated gradients to the model's trainable variables using the specified optimizer.\n    gradients = tape.gradient(loss, transformer.trainable_variables)    \n    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n    \n    #records the training loss\n    train_loss(loss)\n  ","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:49:22.617621Z","iopub.execute_input":"2023-12-27T00:49:22.618318Z","iopub.status.idle":"2023-12-27T00:49:22.625457Z","shell.execute_reply.started":"2023-12-27T00:49:22.618284Z","shell.execute_reply":"2023-12-27T00:49:22.624377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate():\n    print('validation started ...')\n    val_loss.reset_states()\n    for (batch, (inp, tar)) in enumerate(dataset_val):    \n        tar_inp = tar[:, :-1] # <go> ...\n        tar_real = tar[:, 1:] #  ... <stop>\n\n        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n        \n        predictions, _ = transformer(\n            inp, tar_inp, \n            False, \n            enc_padding_mask, \n            combined_mask, \n            dec_padding_mask\n        )\n        \n        loss = loss_function(tar_real, predictions)\n        val_loss(loss)\n        \n    print('\\n* Validation loss: {} '.format(val_loss.result()) )\n    return val_loss.result()\n# validate()","metadata":{"execution":{"iopub.status.busy":"2023-12-27T00:49:23.358770Z","iopub.execute_input":"2023-12-27T00:49:23.359128Z","iopub.status.idle":"2023-12-27T00:49:23.365995Z","shell.execute_reply.started":"2023-12-27T00:49:23.359100Z","shell.execute_reply":"2023-12-27T00:49:23.364925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nfor epoch in range(EPOCHS):\n    start = time.time()\n\n    train_loss.reset_states()\n  \n    for (batch, (inp, tar)) in enumerate(dataset):\n        #It computes gradients, applies them to update model parameters, and accumulates the training loss.\n        train_step(inp, tar)\n    \n        if batch % 429 == 0:\n            print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, train_loss.result()))\n            \n    val_loss_ = validate().numpy()\n    history['val'].append((epoch,val_loss_))\n    \n    print ('\\n* Train Loss {:.4f}'.format(train_loss.result()))\n    history['train'].append((epoch,train_loss.result().numpy()))\n\n    print ('Epoch {} Loss {:.4f}'.format(epoch + 1, train_loss.result()))\n    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist(history)","metadata":{"execution":{"iopub.status.busy":"2023-12-26T17:15:48.020561Z","iopub.execute_input":"2023-12-26T17:15:48.021389Z","iopub.status.idle":"2023-12-26T17:15:48.360383Z","shell.execute_reply.started":"2023-12-26T17:15:48.021354Z","shell.execute_reply":"2023-12-26T17:15:48.359507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nfor epoch in range(EPOCHS):\n    start = time.time()\n\n    train_loss.reset_states()\n  \n    for (batch, (inp, tar)) in enumerate(dataset):\n        train_step(inp, tar)\n    \n        if batch % 429 == 0:\n            print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, train_loss.result()))\n            \n    val_loss_ = validate().numpy()\n    history['val'].append((epoch,val_loss_))\n    print ('\\n* Train Loss {:.4f}'.format(train_loss.result()))\n    history['train'].append((epoch,train_loss.result().numpy()))\n\n    print ('Epoch {} Loss {:.4f}'.format(epoch + 1, train_loss.result()))\n    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))","metadata":{"execution":{"iopub.status.busy":"2023-12-26T17:30:21.800586Z","iopub.execute_input":"2023-12-26T17:30:21.801409Z","iopub.status.idle":"2023-12-26T18:59:12.360674Z","shell.execute_reply.started":"2023-12-26T17:30:21.801374Z","shell.execute_reply":"2023-12-26T18:59:12.359652Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist(history)","metadata":{"execution":{"iopub.status.busy":"2023-12-26T19:01:02.213504Z","iopub.execute_input":"2023-12-26T19:01:02.213970Z","iopub.status.idle":"2023-12-26T19:01:02.510829Z","shell.execute_reply.started":"2023-12-26T19:01:02.213934Z","shell.execute_reply":"2023-12-26T19:01:02.509948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **<span style=\"color:darkred\">Inference**","metadata":{}},{"cell_type":"markdown","source":"Predicting on unseen data","metadata":{}},{"cell_type":"code","source":"def evaluate(input_document):\n    input_document = text_tokenizer.texts_to_sequences([input_document])\n    input_document = tf.keras.preprocessing.sequence.pad_sequences(input_document, maxlen=encoder_maxlen, padding='post', truncating='post')\n\n    encoder_input = tf.expand_dims(input_document[0], 0)\n\n    decoder_input = [summary_tokenizer.word_index[\"<go>\"]]\n    output = tf.expand_dims(decoder_input, 0)\n    \n    for i in range(decoder_maxlen):\n        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n\n        predictions, attention_weights = transformer(\n            encoder_input, \n            output,\n            False,\n            enc_padding_mask,\n            combined_mask,\n            dec_padding_mask\n        )\n        #\n        predictions = predictions[: ,-1:, :]\n        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n\n        if predicted_id == summary_tokenizer.word_index[\"<stop>\"]:\n            return tf.squeeze(output, axis=0), attention_weights\n\n        output = tf.concat([output, predicted_id], axis=-1)\n\n    return tf.squeeze(output, axis=0), attention_weights\n\n\ndef summarize(input_document):\n    # not considering attention weights for now, can be used to plot attention heatmaps in the future\n    summarized = evaluate(input_document=input_document)[0].numpy()\n    summarized = np.expand_dims(summarized[1:], 0)  # not printing <go> token\n    \n    return summary_tokenizer.sequences_to_texts(summarized)[0]  # since there is just one translated document","metadata":{"execution":{"iopub.status.busy":"2023-12-26T17:16:53.165757Z","iopub.execute_input":"2023-12-26T17:16:53.166390Z","iopub.status.idle":"2023-12-26T17:16:53.176425Z","shell.execute_reply.started":"2023-12-26T17:16:53.166358Z","shell.execute_reply":"2023-12-26T17:16:53.175501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Try n°1:","metadata":{}},{"cell_type":"code","source":"i=51560\nprint(text[i])\nprint()\nprint((summary[i]))\nprint()\nprint(summarize(summary[i]))","metadata":{"execution":{"iopub.status.busy":"2023-12-26T19:15:17.783549Z","iopub.execute_input":"2023-12-26T19:15:17.784251Z","iopub.status.idle":"2023-12-26T19:15:26.556443Z","shell.execute_reply.started":"2023-12-26T19:15:17.784220Z","shell.execute_reply":"2023-12-26T19:15:26.555451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Try n°2:","metadata":{}},{"cell_type":"code","source":"summarize(\"add music to the background during certain games and activities or allow sound\\\neffects to play every time a button or link is clicked on within the website when children\\\ninteract with happy characters they may be influenced to revisit the website again in the\\\nfuture due to having a positive experience of their own use animations or photos of real people\\\nwho are smiling and displaying positive nonthreatening body language \")","metadata":{"execution":{"iopub.status.busy":"2023-12-26T19:13:22.149022Z","iopub.execute_input":"2023-12-26T19:13:22.149871Z","iopub.status.idle":"2023-12-26T19:13:27.801629Z","shell.execute_reply.started":"2023-12-26T19:13:22.149830Z","shell.execute_reply":"2023-12-26T19:13:27.800664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **<span style=\"color:darkblue\">  Conclusion**\n\nThis is one of the most challenging NLP tasks as it requires a range of abilities, such as understanding long passages and generating coherent text that captures the main topics in a document. \nHowever, when done well, text summarization is a powerful tool that can speed up various business processes by relieving the burden of domain experts to read long documents in detail.","metadata":{}},{"cell_type":"markdown","source":"## **<span style=\"color:darkblue\"> References**\n    \n* https://www.turing.com/kb/brief-introduction-to-transformers-and-their-power\n* https://jalammar.github.io/illustrated-transformer/","metadata":{}},{"cell_type":"markdown","source":"<!-- Centering the image -->\n<div style=\"text-align:center\">\n  <!-- Inserting the image with a URL or file path -->\n  <img src=\"https://i.ibb.co/yWVQ6x8/bro.png\" alt=\"decod\" width=\"900\" height=\"600\">\n</div>","metadata":{}}]}